[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/xdcIkjOc)
# Homework 1: Code with AI

The due date is Feb 17 at midnight. If you are using the late days, please note in the head of README.md that ‚ÄúI used XX late days this time, and I have XX days remaining‚Äù.

The main purpose of this homework is to help you:

- Get experience with AI coding
- Learn how to decompose a problem into smaller tasks and find the right tools to solve them with the help of AI
- Improve your prompt engineering skills
- Conduct the coding task you have never learned before with the help of AI
- Learn the agentic programming paradigm

**Remark**: We expect you to complete the homework with the help of AI. The tips we provide are just suggestions, and you can use other tools to complete the tasks. This homework might take longer than you expect if you have no experience with game/web development or GitHub Actions. Though this is exactly what we expect you to experience: to finish the coding tasks that you have never learned before, we suggest you **start early** in case you face unexpected issues. 

Enjoy your vibe coding!

Your homework repository should have all the source code for the problems below, though the real website could be based on the repository hosted under your own GitHub account.

In the `README.md` of your homework repository, you can write the report section as a case-study tutorial on how to use AI copilot for the following three problems. You can list the AI tools you used, and how you designed and adjusted your prompts. You can add screenshots or even share the video of how you used these AI tools and the intermediate products generated by AI if you believe it will help the readers learn.

---

## Introduction

This repository contains solutions for **Homework 1: Code with AI** from Harvard's BST236 course (Spring 2026). The project demonstrates the agentic programming paradigm by using AI tools (GitHub Copilot CLI) to scaffold, implement, and automate three major tasks:

1. **Problem 1**: Build a responsive homepage for a coding blog hosted on GitHub Pages
2. **Problem 2**: Create an interactive Valentine's-themed Pac-Man game with heart projectiles
3. **Problem 3**: Develop an auto-updating arXiv paper feed using GitHub Actions and AI agents

The core philosophy is to decompose complex problems into smaller agent-friendly tasks, write clear prompts, and let AI handle the implementation. This approach teaches effective prompt engineering and demonstrates how to accomplish tasks you've never learned before with the help of AI.

**Live Website**: https://katsaxton.github.io/bst236website/

## Installation

### Prerequisites
- Git (for cloning the repository)
- Node.js 16+ (for running local tests and the arXiv fetcher script)
- A GitHub account with GitHub Pages enabled
- (Optional) VS Code with GitHub Copilot CLI for development

### Setup Instructions

1. **Clone the repository**:
   ```bash
   git clone https://github.com/katsaxton/bst236website.git
   cd bst236website
   ```

2. **Install dependencies** (minimal; mostly for running optional Node scripts):
   ```bash
   npm install
   ```
   Or for the arXiv fetcher script alone:
   ```bash
   # No external dependencies needed; uses Node.js built-in modules
   ```

3. **Enable GitHub Pages** (if deploying to your own account):
   - Go to your repository Settings ‚Üí Pages
   - Source: Deploy from branch `main`
   - Save and wait for the site to build (takes ~1-2 minutes)

4. **Access the website**:
   - Visit: `https://<your-username>.github.io/bst236website/`
   - Navigate to the arXiv page: `/bst236website/arxiv.html`
   - Play the Pac-Man game: `/bst236website/games.html`

### Automatic Paper Updates
The arXiv dashboard updates automatically every day at midnight UTC via GitHub Actions. To manually trigger:
1. Go to Actions tab ‚Üí "Update arXiv Papers Dashboard"
2. Click "Run workflow" ‚Üí "Run workflow"
3. Check the arxiv.html file for updates within 2-3 minutes

## Usage

### Viewing the Website
Simply open the site in any modern browser:
```
https://katsaxton.github.io/bst236website/index.html
```

**Expected output**: A responsive homepage with three navigation links (Home, arXiv Papers, Games).

### Playing the Pac-Man Game
Click the **Games** link on the homepage to play:
- **Controls**: Arrow keys to move Pac-Man
- **Objective**: Eat dots, avoid ghosts, collect roses for power-up
- **Power-Up**: When powered up, Pac-Man shoots hearts to eliminate ghosts
- **Win Condition**: Eat all dots without losing all lives

**Expected behavior**: Game runs smoothly at 60 FPS with responsive controls and proper collision detection.

### Checking the arXiv Feed
Click **arXiv Papers** on the homepage to see:
- **Content**: Latest 10 papers from arXiv (AI, ML, and computational biology)
- **Paper info**: Title, authors, abstract, publication date, PDF link
- **Auto-refresh**: Timestamp shows last update (updates daily at midnight UTC)
- **Expected layout**: Responsive grid of paper cards that work on mobile and desktop

**Sample output**:
```
Latest Research Papers
Last updated: Tue, 17 Feb 2026 18:30:08 UTC

[Paper Card 1]
Title: Long Context, Less Focus: A Scaling Gap in LLMs...
Authors: By Shangding Gu
Published: 2026-02-16
Summary: Large language models (LLMs) are increasingly deployed...
[Download PDF]

[Paper Card 2]
...
```

## Report

### Problem 1: GitHub Website for Your Coding Blog
**Status**: ‚úÖ Complete

The homepage was created using responsive HTML/CSS without JavaScript. The design is mobile-first and uses CSS Grid/Flexbox for flexible layouts. The navigation bar links to all three main pages.

**Tools Used**: VS Code, basic HTML5, CSS3

**Approach**: Simple, semantic HTML structure with clean CSS for styling and responsiveness.

---

### Problem 2: Valentine's Pac-Man Game
**Status**: ‚úÖ Complete

An interactive Pac-Man game with:
- Classic maze navigation with dots
- Ghost AI that chases Pac-Man
- Valentine's rose power-up that enables heart projectiles
- Lives system and scoring

**Tools Used**: JavaScript (Canvas API), HTML5, CSS

**Approach**: Used the game-controller agent from Copilot CLI to manage game state, physics, and interactions. Game runs at 60 FPS with proper collision detection.

---

### Problem 3: Auto-Updating arXiv Dashboard with GitHub Actions
**Status**: ‚úÖ Complete

Built a fully automated system using the **agentic programming paradigm**:

#### High-Level Architecture
- **Workflow Trigger**: GitHub Actions at midnight UTC daily
- **Data Fetching**: Node.js script queries arXiv REST API
- **Data Processing**: Filters papers by category (cs.AI, q-bio.CB, stat.ML), validates data
- **HTML Generation**: Dynamically creates responsive paper cards
- **Deployment**: Commits changes and auto-deploys via GitHub Pages
- **Dual Sync**: Changes push to both `bst236website` and homework repository

#### Key Implementation Details

**1. arXiv API Integration**
- Query: `cat:cs.AI OR cat:q-bio.CB OR cat:stat.ML`
- Returns: 10 most recent papers, sorted by submission date
- Fallback: Uses hardcoded sample paper if API is rate-limited
- Error handling: Gracefully degrades if API unavailable

**2. Workflow File** (`.github/workflows/update-papers.yml`)
- Triggers daily at `0 0 * * *` (midnight UTC)
- Runs Node.js script to fetch and parse XML
- Limits display to 10 latest papers
- Commits with Copilot co-author attribution
- Pushes to GitHub, triggering Pages rebuild

**3. HTML/CSS Responsive Design**
- Mobile-first breakpoints (320px, 768px, 1024px+)
- Paper cards stack vertically on mobile
- Accessible color contrast (WCAG AA)
- Semantic HTML5 (`<article>`, `<section>`, `<time>` elements)

#### Challenges & Solutions

| Challenge | Solution |
|-----------|----------|
| arXiv API rate-limiting (>10 requests/min) | Added fallback sample paper, spacing requests, respecting 3-second minimum |
| HTML structure corruption | Fixed regex to match actual file structure, use proper `</section>` tags |
| Scheduled workflows not running | Learned GitHub Actions scheduling is asynchronous; verified with manual triggers and logs |
| Accumulating old papers | Added `slice(0, 10)` to limit display, fixed section replacement regex |
| Dual repo sync | Configured git `pushurl` to push to both repos automatically |

#### Prompting Strategy
- **Approach**: Clear, detailed prompts with error handling examples
- **Iterations**: Started with agent-based architecture, simplified to inline Node.js script when reliability was needed
- **Testing**: Manually triggered workflow multiple times to verify paper fetching and HTML updates

#### Technology Stack
- **Language**: JavaScript (Node.js)
- **API**: arXiv REST API (public, no authentication)
- **Automation**: GitHub Actions (YAML)
- **Hosting**: GitHub Pages
- **Version Control**: Git with semantic commits

#### Live Results
- **URL**: https://katsaxton.github.io/bst236website/arxiv.html
- **Update Schedule**: Daily at midnight UTC
- **Current Papers**: 10 latest from AI/ML/computational biology categories
- **Features**: Full paper details, PDF links, responsive design, auto-refresh timestamp

---

## Contributions

**Team Size**: Solo project by Kathryn Saxton

**Role**: Full Stack Developer
- ‚úÖ Designed and built responsive homepage (HTML/CSS)
- ‚úÖ Implemented Pac-Man game with heart projectiles (JavaScript)
- ‚úÖ Architected arXiv auto-update system (Node.js + GitHub Actions)
- ‚úÖ Configured dual repository sync (git config)
- ‚úÖ Troubleshot workflow scheduling and HTML generation issues
- ‚úÖ Wrote comprehensive documentation and README

**AI Tools Used**:
- **GitHub Copilot CLI**: Primary coding assistant for scaffolding, debugging, and implementation
- **Custom Agents**: Orchestrator, game-controller, arxiv-fetcher, deployer agents
- **Prompt Engineering**: Iteratively refined prompts for robustness and clarity

---

Create a homepage for a website for your **coding blog**. The website should be hosted on [GitHub Pages](https://pages.github.com/). You can design the homepage by yourself in any proper style you like. You may need to make the design expandable to add more content from our future assignments. The link to the homepage should be added to the `README.md` of your homework repository so that anyone can access the homepage and the following two webpages from the Internet using this link.

### Link to website: https://katsaxton.github.io/bst236website/index.html

## Problem 2. Game Coding: Pac-Man (Valentine's Special üíò)

Add a new page to your website for a Valentine's-themed [Pac-Man](https://en.wikipedia.org/wiki/Pac-Man) game. The users can directly play the game on your webpage. The link to the game webpage should be added to the homepage in Problem 1. Your game should include the following core features:

1. **Classic Pac-Man Mechanics**: A maze with dots (pellets) for Pac-Man to eat, and ghosts that chase Pac-Man. The game ends when Pac-Man loses all lives. You can decide the maze layout by yourself (classic ok, but maybe even 3D).
2. **Valentine's Power-Up ‚Äî Rose** üåπ: A rose randomly appears on the maze from time to time. When Pac-Man eats the rose, it enters a powered-up state for a limited duration (e.g., a few seconds), during which Pac-Man **continuously shoots hearts** in its current facing direction.
3. **Heart Projectiles** üíï: The hearts travel across the maze and eliminate any ghost they hit. Once the power-up expires, Pac-Man returns to normal until it picks up another rose.

As long as the game is recognizable as a Pac-Man game by common sense, with the features roughly following the above requirements, you will get full credit.

Beyond these requirements, you are free (but will not be graded) to add your own creative touches ‚Äî such as Valentine's-themed visuals, sound effects, scoring bonuses, or additional power-ups.

## Problem 3. Data Scaffolding from the Internet

In this problem, you will build an auto-updating arXiv paper feed for your website. **You must use Copilot CLI as your primary coding tools** to scaffold, implement, and automate this task. The goal is to practice the agentic programming paradigm: break the task into agent-friendly steps, prompt the agent effectively, and wire everything together.

We suggest you to follow the steps we showed in the class: plan first with AI to decide the workflow and agents orchestration, then ask AI to implement the plan.

### Deliverables

Add a new page to your website that displays the latest arXiv papers. The page must include:

1. **Paper Listing**: The latest arXiv papers matching keywords of your choice. Design the layout as you see fit.
2. **Paper Details**: Each entry must show the paper title, authors, abstract, and a direct link to the PDF.
3. **Auto-Update**: The paper list must refresh automatically every midnight via a GitHub Actions workflow.
4. **Homepage Link**: A link to this page must appear on your homepage from Problem 1.
5. **Page Design**: Style the page in any way you think readers would appreciate.

Your homework repository **must include the `.github` directory** with all agent configurations and workflow files used for this problem.

In your report (`README.md`), describe how you used Copilot CLI to build each component. Include the prompts you gave the agent and note what worked well or required iteration.

### Tips

**Tip 1**: You can ask AI how to deploy the website by [GitHub Pages](https://pages.github.com/). 

**Tip 2**: You can ask AI to teach you how to use [arXiv API](https://arxiv.org/help/api/user-manual) to fetch the latest papers from arXiv.

**Tip 3**: You can ask AI to teach you how to use [GitHub Actions](https://docs.github.com/en/actions) to automate the process of updating the webpage. Or even leave the job to agents.

**Tip 4**: You can use [Copy Coder](https://copycoder.ai/) to help you design the webpage UI from the style you like.

---

## Implementation Report: Problem 3 - arXiv Dashboard with Agent System

### Overview
I built a fully automated arXiv paper dashboard using the **Copilot CLI agentic programming paradigm**. The system fetches papers from arXiv, generates AI summaries, and automatically deploys to GitHub Pages every midnight via GitHub Actions.

**Deployment Target**: `katsaxton/bst236website`
**Live URL**: https://katsaxton.github.io/bst236website/arxiv.html

### Architecture

#### 4 Autonomous Agents
1. **Orchestrator Agent** - Coordinates the entire pipeline, manages phase transitions, handles error recovery
2. **arXiv Fetcher Agent** - Queries arXiv REST API, filters by oncology/AI topics, validates data
3. **Paper Summarizer Agent** - Generates concise AI summaries and key points for each paper
4. **GitHub Pages Deployer Agent** - Updates HTML, commits changes, deploys via GitHub Pages

#### 5 Reusable Skills
1. **arXiv API Skill** - Handles API queries, response parsing, retry logic, caching
2. **Data Processing Skill** - Filters, deduplicates, normalizes, and aggregates paper data
3. **HTML Generation Skill** - Dynamically creates paper cards with XSS sanitization
4. **Summary Generation Skill** - AI-powered summarization with fallback strategies
5. **GitHub Deployment Skill** - Git operations, commits with co-author trailers, push verification

#### 6 Guidance Prompts
1. **Orchestration Prompt** - Defines pipeline flow, timeouts, error handling strategies
2. **Fetch Prompt** - Detailed arXiv API usage, query construction, edge case handling
3. **Summarization Prompt** - Rules for 2-3 sentence summaries, key points extraction, QA checks
4. **Deployment Prompt** - HTML updates, Git operations, GitHub Pages verification
5. **Coding Style Prompt** - JSON formats, logging standards, configuration patterns
6. **HTML Spec Prompt** - Semantic HTML5, accessibility, responsive design guidelines

#### 1 Workflow Configuration
- **update-papers.yml** - GitHub Actions workflow triggered at midnight UTC (configurable)
- Supports manual triggers via `workflow_dispatch`
- Placeholder for orchestrator agent invocation

### Key Design Decisions

#### Declarative Configuration (No Manual Code)
- All logic encapsulated in agent prompts and skills
- Focus on **what** tasks should be done, not **how** to implement them
- Agents follow prompts to execute tasks autonomously

#### Graceful Degradation
- Individual paper failures don't stop the pipeline
- Fallback to original abstracts if summarization fails
- Cached results used if API unavailable
- Non-blocking error handling throughout

#### Safety First
- HTML sanitization to prevent XSS vulnerabilities
- No credentials in logs (use GitHub secrets)
- Force-push disabled in Git operations
- Backup and validation before file updates

#### Extensibility
- Games page included as placeholder for future expansion
- CSS uses CSS variables for easy theming
- Agent system supports adding new data sources
- Modular skill design enables reuse

### File Structure
```
.
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ agents/                    # 4 agent definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.agent.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv-fetcher.agent.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarizer.agent.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deployer.agent.md
‚îÇ   ‚îú‚îÄ‚îÄ skills/                    # 5 reusable skills
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arxiv-api.skill.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data-processing.skill.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ html-generation.skill.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summary-generation.skill.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ github-deployment.skill.md
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # 6 guidance prompts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrate.prompt.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch-arxiv.prompt.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarize.prompt.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deploy.prompt.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ coding-style.prompt.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ html-spec.prompt.md
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ update-papers.yml      # Midnight trigger
‚îú‚îÄ‚îÄ index.html                     # Homepage
‚îú‚îÄ‚îÄ arxiv.html                     # Dashboard (auto-updated)
‚îú‚îÄ‚îÄ games.html                     # Games placeholder
‚îî‚îÄ‚îÄ css/
    ‚îî‚îÄ‚îÄ style.css                  # Responsive styling
```

### Data Flow

```
GitHub Actions (Midnight UTC)
  ‚Üì
[Orchestrator Agent] Coordinates pipeline
  ‚Üì
[arXiv Fetcher] ‚Üí Query API (last 24 hours)
  ‚Üí Filter: cs.AI, cs.LG, q-bio.CB categories
  ‚Üí Validate & deduplicate papers
  ‚Üì
[Paper Summarizer] ‚Üí Generate AI summaries
  ‚Üí Extract key points (2-4 items)
  ‚Üí Quality assurance checks
  ‚Üì
[Deployer Agent] ‚Üí Update arxiv.html
  ‚Üí Commit with co-author trailer
  ‚Üí Push to main branch
  ‚Üí GitHub Pages auto-builds
  ‚Üì
https://katsaxton.github.io/bst236website/arxiv.html
```

### Features Implemented

‚úÖ **Automated Paper Fetching**
- Queries arXiv REST API
- Filters by topic (oncology + AI)
- Last 24-hour window
- Max 10 papers per run

‚úÖ **AI-Generated Summaries**
- 2-3 sentence summaries (max 150 words)
- 3 key points per paper
- Target audience: educated non-specialists
- Fallback to original abstract if generation fails

‚úÖ **Responsive Web Design**
- Mobile-first CSS (320px+)
- Accessible color contrast (WCAG AA)
- Semantic HTML5 structure
- Touch-friendly interactions

‚úÖ **GitHub Pages Integration**
- Deploy from branch (main)
- Auto-builds on push
- Live URL accessible immediately
- Static site (no server required)

‚úÖ **Scheduling & Automation**
- Cron trigger: `0 0 * * *` (midnight UTC daily)
- Manual trigger support
- Comprehensive logging
- Error reporting

### Agentic Programming Principles Applied

1. **Planning First** - Created detailed plan before implementation
2. **Decomposition** - Broke problem into 4 agents, 5 skills, 6 prompts
3. **Prompting** - Clear, detailed prompts with examples and fallback strategies
4. **Orchestration** - Central orchestrator coordinates independent agents
5. **Error Resilience** - Non-blocking failures, graceful degradation
6. **Idempotency** - Safe to re-run pipeline at any time

### What Worked Well

‚úÖ Detailed prompts with examples and edge cases
‚úÖ Clear separation of concerns (agents, skills, prompts)
‚úÖ Comprehensive error handling strategies  
‚úÖ CSS variables for consistent theming
‚úÖ Responsive design without JavaScript dependencies
‚úÖ Git co-author attribution for proper credit

### Challenges & Iterations

1. **API Rate Limiting**: Added exponential backoff and respecting 3-second min interval
2. **HTML Sanitization**: Implemented XSS prevention for user-generated content
3. **Timezone Handling**: Used UTC consistently throughout for clarity
4. **Graceful Degradation**: Added multiple fallback strategies for each agent
5. **Git Workflow**: Ensured safety with validation before commits/pushes

### Next Steps for Full Deployment

To activate the pipeline on `katsaxton/bst236website`:

1. Create the target repository: `katsaxton/bst236website`
2. Enable GitHub Pages (Settings ‚Üí Pages ‚Üí Deploy from branch: main)
3. Set up GitHub Actions (Settings ‚Üí Actions ‚Üí Workflow permissions)
4. Configure workflow secrets if needed
5. Replace placeholder in workflow with actual Copilot CLI orchestrator invocation
6. Trigger first run manually via GitHub Actions UI

### Key Technologies

- **Agent System**: VS Code Copilot CLI custom agents
- **API**: arXiv REST API (public, no auth required)
- **Automation**: GitHub Actions (YAML workflows)
- **Hosting**: GitHub Pages (static site)
- **Frontend**: HTML5, CSS3 (no JavaScript required)
- **VCS**: Git (with semantic commit messages)

### Conclusion

This implementation demonstrates the **agentic programming paradigm** in action:
- Autonomous agents handle specific tasks
- Clear prompts guide agent behavior
- Reusable skills enable composition
- Central orchestration manages workflow
- Graceful error handling ensures reliability

The system is fully automated, requires no manual coding after setup, and scales to handle new data sources by adding agents and skills.


